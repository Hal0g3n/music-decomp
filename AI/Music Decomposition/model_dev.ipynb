{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.8.0-cp38-cp38-win_amd64.whl (438.0 MB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Collecting gast>=0.2.1\n",
      "  Downloading gast-0.5.3-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.20.1)\n",
      "Collecting tensorboard<2.9,>=2.8\n",
      "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "Collecting keras<2.9,>=2.8.0rc0\n",
      "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.24.0-cp38-cp38-win_amd64.whl (1.5 MB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (3.7.4.3)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting absl-py>=0.4.0\n",
      "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (52.0.0.post20210125)\n",
      "Collecting protobuf>=3.9.2\n",
      "  Downloading protobuf-3.19.4-cp38-cp38-win_amd64.whl (895 kB)\n",
      "Collecting libclang>=9.0.1\n",
      "  Downloading libclang-13.0.0-py2.py3-none-win_amd64.whl (13.9 MB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.44.0-cp38-cp38-win_amd64.whl (3.4 MB)\n",
      "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
      "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Collecting flatbuffers>=1.12\n",
      "  Downloading flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.36.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.25.1)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\user\\anaconda3\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.6.2-py2.py3-none-any.whl (156 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Downloading importlib_metadata-4.11.3-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.4.1)\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=b48442b91e323137b8c234f9b3b6f833e5920478e29ff05e650c886d3a1cd1d4\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\a0\\16\\9c\\5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built termcolor\n",
      "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, tensorboard-plugin-wit, tensorboard-data-server, protobuf, markdown, grpcio, google-auth-oauthlib, absl-py, tf-estimator-nightly, termcolor, tensorflow-io-gcs-filesystem, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 3.10.0\n",
      "    Uninstalling importlib-metadata-3.10.0:\n",
      "      Successfully uninstalled importlib-metadata-3.10.0\n",
      "Successfully installed absl-py-1.0.0 astunparse-1.6.3 cachetools-5.0.0 flatbuffers-2.0 gast-0.5.3 google-auth-2.6.2 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.44.0 importlib-metadata-4.11.3 keras-2.8.0 keras-preprocessing-1.1.2 libclang-13.0.0 markdown-3.3.6 oauthlib-3.2.0 opt-einsum-3.3.0 protobuf-3.19.4 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 rsa-4.8 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.0 tensorflow-io-gcs-filesystem-0.24.0 termcolor-1.1.0 tf-estimator-nightly-2.8.0.dev2021122109\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting solos\n",
      "  Downloading solos-0.4.1-py3-none-any.whl (65 kB)\n",
      "Collecting youtube-dl\n",
      "  Downloading youtube_dl-2021.12.17-py2.py3-none-any.whl (1.9 MB)\n",
      "Collecting googledrivedownloader\n",
      "  Downloading googledrivedownloader-0.4-py2.py3-none-any.whl (3.9 kB)\n",
      "Collecting Fire\n",
      "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
      "Requirement already satisfied: six in c:\\users\\user\\anaconda3\\lib\\site-packages (from Fire->solos) (1.15.0)\n",
      "Requirement already satisfied: termcolor in c:\\users\\user\\anaconda3\\lib\\site-packages (from Fire->solos) (1.1.0)\n",
      "Building wheels for collected packages: Fire\n",
      "  Building wheel for Fire (setup.py): started\n",
      "  Building wheel for Fire (setup.py): finished with status 'done'\n",
      "  Created wheel for Fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115928 sha256=6e08bcb59399806145c16cf0e7d2fd73e505fe50711c178a67878f03719e534f\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\1f\\10\\06\\2a990ee4d73a8479fe2922445e8a876d38cfbfed052284c6a1\n",
      "Successfully built Fire\n",
      "Installing collected packages: youtube-dl, googledrivedownloader, Fire, solos\n",
      "Successfully installed Fire-0.4.0 googledrivedownloader-0.4 solos-0.4.1 youtube-dl-2021.12.17\n"
     ]
    }
   ],
   "source": [
    "!pip install solos"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting soundfile\n",
      "  Downloading SoundFile-0.10.3.post1-py2.py3.cp26.cp27.cp32.cp33.cp34.cp35.cp36.pp27.pp32.pp33-none-win_amd64.whl (689 kB)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from soundfile) (1.14.5)\n",
      "Requirement already satisfied: pycparser in c:\\users\\user\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile) (2.20)\n",
      "Installing collected packages: soundfile\n",
      "Successfully installed soundfile-0.10.3.post1\n"
     ]
    }
   ],
   "source": [
    "!pip install soundfile"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import json\n",
    "from pathlib import Path\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "import soundfile as sf"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class DataManager:\n",
    "    def __init__(self, data_dir, mix_no_min=2, training=True, mix_sources_max_no=4, mix_no_max=7, train_test_split=0.8):\n",
    "\n",
    "        self.data_dir = data_dir\n",
    "        self.type = training\n",
    "        self.multimodal = False\n",
    "        self.mix_no_min = mix_no_min\n",
    "        self.mix_no_max = mix_no_max\n",
    "        self.mix_sources_max_no = mix_sources_max_no\n",
    "        self.train_test_split = train_test_split\n",
    "\n",
    "        self.n_instruments = 13\n",
    "        self.sources = ['Bassoon', 'Cello', 'Clarinet', 'DoubleBass', 'Flute',\n",
    "                        'Horn', 'Oboe', 'Saxophone', 'Trombone', 'Trumpet', 'Tuba', 'Viola', 'Violin']\n",
    "\n",
    "\n",
    "        self.source_weights = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
    "        self.down_freq = 8000 # Downsample to this frequency\n",
    "        self.audio_len = 48000 # No of audio samples in each 'snapshot'\n",
    "        self.ft_window_size = 1022\n",
    "        self.ft_hop_size = 256\n",
    "        self.epsilon = 1e-9\n",
    "        self.log_sample_n = 256 # TODO No idea what this does, I'll figure it out later\n",
    "        self.segment_len = 256\n",
    "        self.energy_predicted_sum = 1e-4\n",
    "        self.dummy_spectrogram_size = (14, 2, 512, 256) # For tests\n",
    "\n",
    "        self.metadata = self.load_meta()\n",
    "        self.window = tf.signal.hann_window(self.ft_hop_size)\n",
    "\n",
    "        self.data = {}\n",
    "        self.load_data()\n",
    "\n",
    "        # We will be taking the results seen in papers at face value,\n",
    "        # and using normalised linearised Fourier Transform Spectrogram, and Wiener post processing, alongside ratio masks and L2 loss\n",
    "\n",
    "    def increase_n_mix(self):\n",
    "        if self.n_mix_max < self.mix_sources_max_no:\n",
    "            self.n_mix_max += 1\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "\n",
    "    def load_meta(self):\n",
    "        suffix = \"*.wav\" # Audio file type\n",
    "        meta = dict([(source, sorted(list((Path(self.data_dir) / source).glob(suffix)))) for source in self.sources])\n",
    "        # A little hard to parse, but here we go\n",
    "        # Makes \"meta\" a dict containing a tuple. The first element is the type of source, i.e. viola, trumpet, etc\n",
    "        # The second is a sorted list of all files in the data directory that match the pattern of source.wav\n",
    "        # (.glob is an operation that yields all file paths matching the pattern)\n",
    "\n",
    "        for source in meta:\n",
    "            source_len = len(meta[source])\n",
    "            if self.type: # True means that it's training\n",
    "                meta[source] = meta[source_len][:int(self.train_test_split * source_len)]\n",
    "            else:\n",
    "                meta[source] = meta[source_len][int(self.train_test_split * source_len) : source_len]\n",
    "            # Literally just a slightly clumsy train test split\n",
    "\n",
    "            for path_index, path in enumerate(meta[source]):\n",
    "                meta[source][path_index] = (path, sf.info(path.as_posix()).frames)\n",
    "        print(meta) # For debugging\n",
    "\n",
    "        return meta\n",
    "\n",
    "\n",
    "    def load_data(self):\n",
    "        for source in self.metadata:\n",
    "            temp = []\n",
    "            for filename, length in self.metadata[source]:\n",
    "                temp.append(tf.constant(\n",
    "                    sf.read(filename.asposix())[0]\n",
    "                ))\n",
    "                print(filename.asposix()) # For debugging\n",
    "            self.data[source] = temp.copy()\n",
    "        print(self.data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return 8000 if self.type == \"train\" else 2000\n",
    "        # Literally just the size of the thing\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}